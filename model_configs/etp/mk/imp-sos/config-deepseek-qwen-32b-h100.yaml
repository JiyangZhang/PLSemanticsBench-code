batch_size: 4
temperature: 0.6
top_p: 0.95
attention_head: 64
gpu_memory_utilization: 0.95
max_new_tokens: 21000
max_model_len: 32768