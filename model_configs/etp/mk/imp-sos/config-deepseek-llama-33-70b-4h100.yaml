batch_size: 1
temperature: 0.6
top_p: 0.95
attention_head: 64
gpu_memory_utilization: 0.95
max_new_tokens: 24000
max_model_len: 36000
