batch_size: 4
temperature: 0
top_p: 1
attention_head: 40
max_new_tokens: 21000
max_model_len: 32768
gpu_memory_utilization: 0.95
