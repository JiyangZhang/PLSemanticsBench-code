batch_size: 2
temperature: 0.6
top_p: 0.95
attention_head: 40
max_new_tokens: 32768
max_model_len: 40960
gpu_memory_utilization: 0.95
